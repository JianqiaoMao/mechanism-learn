{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The experiment on real-world ICH detection using mechanism learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import causalBootstrapping as cb\n",
    "from distEst_lib import MultivarContiDistributionEstimator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os \n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "rng_bootstrap = np.random.RandomState(42)\n",
    "rng_train_test = np.random.RandomState(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_read(dir_list, img_size):\n",
    "    img_list = []\n",
    "    for dir in dir_list:\n",
    "        img = cv2.imread(dir, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img_list.append(img.flatten())\n",
    "    return np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"../../test_data/ICH_data/\"\n",
    "effect_dir = dir + r\"ct_clean/\"\n",
    "mediator_dir = dir\n",
    "cause_dir = dir\n",
    "imgs_names = os.listdir(effect_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_names = sorted(imgs_names, key=lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_imgs = img_read([effect_dir + img_name for img_name in imgs_names], (128, 128))\n",
    "cause_table = pd.read_csv(cause_dir + \"hemorrhage_diagnosis_ct_clean.csv\")\n",
    "mediator_table = pd.read_csv(mediator_dir + \"mediator_embedding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cause Var Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"No Hemorrhage\", 1: \"Intraventricular\", 2: \"Intraparenchymal\", 3: \"Subarachnoid\", 4: \"Epidural\", 5: \"Subdural\"}\n",
    "\n",
    "cause_table[\"category\"] = np.nan\n",
    "cause_table.loc[cause_table[\"No_Hemorrhage\"] == 1, \"category\"] = 0\n",
    "cause_table.loc[cause_table[\"Intraventricular\"] == 1, \"category\"] = 1\n",
    "cause_table.loc[cause_table[\"Intraparenchymal\"] == 1, \"category\"] = 2\n",
    "cause_table.loc[cause_table[\"Subarachnoid\"] == 1, \"category\"] = 3\n",
    "cause_table.loc[cause_table[\"Epidural\"] == 1, \"category\"] = 4\n",
    "cause_table.loc[cause_table[\"Subdural\"] == 1, \"category\"] = 5\n",
    "cause_table[\"category\"] = cause_table[\"category\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_category = cause_table[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(cause_table[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediator Var Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2    3         4         5    6          7  \\\n",
       "0  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "1  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "2  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "3  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "4  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "\n",
       "     8          9  \n",
       "0  0.0  12.386361  \n",
       "1  0.0  12.386361  \n",
       "2  0.0  12.386361  \n",
       "3  0.0  12.386361  \n",
       "4  0.0  12.386361  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediator_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3\n",
       "0.0    2411\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediator_table['3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the all-zero column\n",
    "mediator_table.drop(columns=['3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format variables and normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_imgs = effect_imgs/255.0\n",
    "cause_category = cause_category.reshape(-1,1)\n",
    "mediaor_values = mediator_table.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate required distributions for causal bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cause_data = {\"Y\": cause_category}\n",
    "mediator_data = {\"Z\": mediaor_values}\n",
    "effect_data = {\"X\": effect_imgs} \n",
    "n_bins_yz = [0]+[6 for i in range(mediaor_values.shape[1])]\n",
    "n_bins_y = [0]\n",
    "\n",
    "joint_yz_data = np.concatenate((cause_category, mediaor_values), axis = 1)\n",
    "\n",
    "dist_estimator_yz = MultivarContiDistributionEstimator(data_fit=joint_yz_data, n_bins = n_bins_yz)\n",
    "pdf_yz, pyz = dist_estimator_yz.fit_histogram()\n",
    "dist_estimator_y = MultivarContiDistributionEstimator(data_fit=cause_category, n_bins = n_bins_y)\n",
    "pdf_y, py = dist_estimator_y.fit_histogram()\n",
    "\n",
    "dist_map = {\"Y,Z\": lambda Y, Z: pdf_yz([Y,Z]),\n",
    "            \"Y',Z\": lambda Y_prime, Z: pdf_yz([Y_prime,Z]),\n",
    "            \"Y\": lambda Y: pdf_y(Y),\n",
    "            \"Y'\": lambda Y_prime: pdf_y(Y_prime)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare inputs for causal bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interventional prob.:p_{Y}(X)=\\sum_{Z,Y'}[p(X|Z,Y')p(Z|Y)p(Y')]\n",
      "Causal bootstrapping weights function: [P(Y')P(Y,Z)]/N*[P(Y',Z)P(Y)]\n",
      "Required distributions:\n",
      "1: P(Y')\n",
      "2: P(Y,Z)\n",
      "3: P(Y',Z)\n",
      "4: P(Y)\n"
     ]
    }
   ],
   "source": [
    "causal_graph = '\"Front-door\"; \\\n",
    "                Y; X; Z; \\\n",
    "                Y -> Z; \\\n",
    "                Z -> X; \\\n",
    "                X <-> Y;'\n",
    "weight_func_lam, weight_func_str = cb.general_cb_analysis(causal_graph = causal_graph, \n",
    "                                                          effect_var_name = 'X', \n",
    "                                                          cause_var_name = 'Y',\n",
    "                                                          info_print = True)\n",
    "N = cause_category.shape[0]\n",
    "w_func = weight_func_lam(dist_map = dist_map, N = N, kernel = None)\n",
    "cause_var_name = list(cause_data.keys())[0]\n",
    "effect_var_name = list(effect_data.keys())[0]\n",
    "mediator_var_name = list(mediator_data.keys())[0]\n",
    "\n",
    "data = {cause_var_name+\"'\": list(cause_data.values())[0]}\n",
    "data.update(effect_data)\n",
    "data.update(mediator_data)\n",
    "n_sample = [1000, 800, 800, 800, 800, 800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training and test datasets by identifying the causal bootstrap indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVal_X_deconf = np.empty((0, effect_imgs.shape[1]))\n",
    "trainVal_Y_deconf = np.empty((0, 1))\n",
    "test_X_deconf = np.empty((0, effect_imgs.shape[1]))\n",
    "test_Y_deconf = np.empty((0, 1))\n",
    "\n",
    "trainVal_X_conf = np.empty((0, effect_imgs.shape[1]))\n",
    "trainVal_Y_conf = np.empty((0, 1))\n",
    "test_X_conf = np.empty((0, effect_imgs.shape[1]))\n",
    "test_Y_conf = np.empty((0, 1))\n",
    "\n",
    "train_size = 0.85\n",
    "weights = np.empty((n_class, N))\n",
    "idx_ib_by_class = []\n",
    "idx_ib_all_unique = []\n",
    "for class_i in range(n_class):\n",
    "    weights_itv = cb.weight_compute(w_func, data, intv_var = {\"Y\":[class_i for i in range(N)]})\n",
    "    # Causal Bootstrapping weights\n",
    "    weights[class_i] = weights_itv\n",
    "    weights_norm = weights_itv/np.sum(weights_itv)\n",
    "    idx_ib = rng_bootstrap.choice(range(N), size = n_sample[class_i], replace = True, p = weights_norm)\n",
    "    idx_ib_by_class.append(list(idx_ib))\n",
    "    idx_ib_unique = np.unique(idx_ib)\n",
    "    idx_ib_all_unique.append(idx_ib_unique)\n",
    "idx_ib_all_unique = np.unique(np.concatenate(idx_ib_all_unique))\n",
    "idx_ib_train = rng_train_test.choice(idx_ib_all_unique, size = int(train_size*idx_ib_all_unique.shape[0]), replace = False)\n",
    "idx_ib_test = np.setdiff1d(idx_ib_all_unique, idx_ib_train)\n",
    "idx_all_test = np.setdiff1d(range(N), idx_ib_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_i in range(n_class):\n",
    "    idx_ib_train_bootstrap = [idx for idx in idx_ib_by_class[class_i] if idx in idx_ib_train]\n",
    "    trainVal_X_deconf = np.concatenate((trainVal_X_deconf, effect_imgs[idx_ib_train_bootstrap, :]), axis = 0)\n",
    "    trainVal_Y_deconf = np.concatenate((trainVal_Y_deconf, np.array([class_i for i in range(len(idx_ib_train_bootstrap))]).reshape(-1,1)), axis = 0)\n",
    "    \n",
    "    idx_ib_test_bootstrap = [idx for idx in idx_ib_by_class[class_i] if idx in idx_ib_test]\n",
    "    test_X_deconf = np.concatenate((test_X_deconf, effect_imgs[idx_ib_test_bootstrap, :]), axis = 0)\n",
    "    test_Y_deconf = np.concatenate((test_Y_deconf, np.array([class_i for i in range(len(idx_ib_test_bootstrap))]).reshape(-1,1)), axis = 0)\n",
    "    \n",
    "trainVal_X_conf = effect_imgs[idx_ib_train, :]\n",
    "trainVal_Y_conf = cause_category[idx_ib_train].reshape(-1,1)\n",
    "test_X_conf = effect_imgs[idx_all_test, :]\n",
    "test_Y_conf = cause_category[idx_all_test].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample the confounded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training set\n",
    "n_rus_train = [np.min([trainVal_Y_deconf[trainVal_Y_deconf == i].shape[0],trainVal_Y_conf[trainVal_Y_conf == i].shape[0]]) for i in range(n_class)]\n",
    "rus_train = RandomUnderSampler(sampling_strategy={i: n_rus_train[i] for i in range(n_class)}, random_state = 42)\n",
    "trainVal_X_conf, trainVal_Y_conf = rus_train.fit_resample(trainVal_X_conf, trainVal_Y_conf)\n",
    "\n",
    "n_ros_train = [trainVal_Y_deconf[trainVal_Y_deconf == i].shape[0] for i in range(n_class)]\n",
    "ros_train = RandomOverSampler(sampling_strategy = {i: n_ros_train[i] for i in range(n_class)}, random_state = 42)\n",
    "trainVal_X_conf, trainVal_Y_conf = ros_train.fit_resample(trainVal_X_conf, trainVal_Y_conf)\n",
    "\n",
    "# Resample the test set\n",
    "n_rus_test = [np.min([test_Y_deconf[test_Y_deconf == i].shape[0],test_Y_conf[test_Y_conf == i].shape[0]]) for i in range(6)]\n",
    "rus_test = RandomUnderSampler(sampling_strategy={i: n_rus_test[i] for i in range(n_class)}, random_state = 42)\n",
    "test_X_conf, test_Y_conf = rus_test.fit_resample(test_X_conf, test_Y_conf)\n",
    "\n",
    "n_ros_test = [test_Y_deconf[test_Y_deconf == i].shape[0] for i in range(n_class)]\n",
    "ros_test = RandomOverSampler(sampling_strategy = {i: n_ros_test[i] for i in range(n_class)}, random_state = 42)\n",
    "test_X_conf, test_Y_conf = ros_test.fit_resample(test_X_conf, test_Y_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the validation set for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconfounded data split\n",
    "val_size = 0.1\n",
    "train_X_deconf, val_X_deconf, train_Y_deconf, val_Y_deconf = train_test_split(trainVal_X_deconf, trainVal_Y_deconf, \n",
    "                                                                              test_size=val_size, stratify=trainVal_Y_deconf, random_state=17)\n",
    "# Confounded data split\n",
    "train_X_conf, val_X_conf, train_Y_conf, val_Y_conf = train_test_split(trainVal_X_conf, trainVal_Y_conf,\n",
    "                                                                      test_size=val_size, stratify=trainVal_Y_conf, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 16  800         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 32)   12832       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 64)  0           ['conv2d_2[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 1)   0           ['input_1[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 64)   0           ['average_pooling2d[0][0]',      \n",
      "                                                                  'average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 16)   1040        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           262208      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 6)            198         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,814\n",
      "Trainable params: 301,814\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def resNetCNN_model(input_shape, num_class):\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    short_cut = input_img\n",
    "    x = layers.Conv2D(16, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.AveragePooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    short_cut = layers.AveragePooling2D((8, 8), padding='same')(short_cut)\n",
    "    x = layers.Add()([x, short_cut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, (1, 1), activation='relu', padding='same')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    encoded = layers.Dense(num_class, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(input_img, encoded)\n",
    "\n",
    "model_deconf = resNetCNN_model((128, 128, 1), n_class)\n",
    "model_deconf.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model_deconf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the deconfounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "950/950 [==============================] - 12s 4ms/step - loss: 1.1732 - accuracy: 0.5308 - val_loss: 0.7261 - val_accuracy: 0.7701\n",
      "Epoch 2/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.6126 - accuracy: 0.7883 - val_loss: 0.4207 - val_accuracy: 0.8626\n",
      "Epoch 3/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.4261 - accuracy: 0.8583 - val_loss: 0.2519 - val_accuracy: 0.9100\n",
      "Epoch 4/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.3339 - accuracy: 0.8847 - val_loss: 0.2589 - val_accuracy: 0.9123\n",
      "Epoch 5/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2870 - accuracy: 0.9018 - val_loss: 0.2216 - val_accuracy: 0.9194\n",
      "Epoch 6/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2714 - accuracy: 0.9131 - val_loss: 0.2182 - val_accuracy: 0.9171\n",
      "Epoch 7/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2284 - accuracy: 0.9244 - val_loss: 0.2262 - val_accuracy: 0.9218\n",
      "Epoch 8/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2221 - accuracy: 0.9273 - val_loss: 0.2493 - val_accuracy: 0.9265\n",
      "Epoch 9/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2068 - accuracy: 0.9329 - val_loss: 0.2148 - val_accuracy: 0.9218\n",
      "Epoch 10/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1976 - accuracy: 0.9381 - val_loss: 0.1750 - val_accuracy: 0.9336\n",
      "Epoch 11/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1828 - accuracy: 0.9392 - val_loss: 0.1679 - val_accuracy: 0.9408\n",
      "Epoch 12/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1847 - accuracy: 0.9421 - val_loss: 0.1814 - val_accuracy: 0.9336\n",
      "Epoch 13/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1763 - accuracy: 0.9458 - val_loss: 0.1823 - val_accuracy: 0.9360\n",
      "Epoch 14/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1693 - accuracy: 0.9439 - val_loss: 0.2147 - val_accuracy: 0.9360\n",
      "Epoch 15/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1557 - accuracy: 0.9492 - val_loss: 0.1860 - val_accuracy: 0.9408\n",
      "Epoch 16/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1754 - accuracy: 0.9444 - val_loss: 0.1749 - val_accuracy: 0.9408\n",
      "Epoch 17/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1617 - accuracy: 0.9471 - val_loss: 0.1607 - val_accuracy: 0.9455\n",
      "Epoch 18/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1414 - accuracy: 0.9550 - val_loss: 0.2649 - val_accuracy: 0.9265\n",
      "Epoch 19/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1547 - accuracy: 0.9502 - val_loss: 0.2111 - val_accuracy: 0.9408\n",
      "Epoch 20/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1536 - accuracy: 0.9518 - val_loss: 0.2054 - val_accuracy: 0.9360\n",
      "Epoch 21/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1713 - accuracy: 0.9455 - val_loss: 0.1754 - val_accuracy: 0.9360\n",
      "Epoch 22/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1371 - accuracy: 0.9542 - val_loss: 0.1732 - val_accuracy: 0.9431\n",
      "Epoch 23/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1437 - accuracy: 0.9534 - val_loss: 0.1792 - val_accuracy: 0.9455\n",
      "Epoch 24/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1603 - accuracy: 0.9473 - val_loss: 0.2079 - val_accuracy: 0.9384\n",
      "Epoch 25/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1377 - accuracy: 0.9550 - val_loss: 0.1740 - val_accuracy: 0.9431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119409c7ca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_deconf_oh = to_categorical(train_Y_deconf.reshape(-1), num_classes=6)\n",
    "val_Y_deconf_oh = to_categorical(val_Y_deconf.reshape(-1), num_classes=6)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=8, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "model_deconf.fit(train_X_deconf.reshape(-1, 128, 128, 1), train_Y_deconf_oh, \n",
    "                 epochs=75, batch_size=4, shuffle=True,\n",
    "                 validation_data=(val_X_deconf.reshape(-1, 128, 128, 1), val_Y_deconf_oh),\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "132/132 [==============================] - 1s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_conf_train = model_deconf.predict(trainVal_X_conf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_conf_test = model_deconf.predict(test_X_conf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_deconf_train = model_deconf.predict(trainVal_X_deconf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_deconf_test = model_deconf.predict(test_X_deconf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_conf_train = np.argmax(Y_pred_conf_train, axis=1)\n",
    "Y_pred_conf_test = np.argmax(Y_pred_conf_test, axis=1)\n",
    "Y_pred_deconf_train = np.argmax(Y_pred_deconf_train, axis=1)\n",
    "Y_pred_deconf_test = np.argmax(Y_pred_deconf_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on confounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       152\n",
      "           1       0.97      1.00      0.99       269\n",
      "           2       0.99      0.93      0.96        95\n",
      "           3       0.83      1.00      0.91        74\n",
      "           4       0.95      0.80      0.87       100\n",
      "           5       0.97      0.83      0.90        90\n",
      "\n",
      "    accuracy                           0.94       780\n",
      "   macro avg       0.93      0.92      0.92       780\n",
      "weighted avg       0.94      0.94      0.94       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_conf.reshape(-1), Y_pred_conf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on deconfounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       152\n",
      "         1.0       0.92      1.00      0.96       269\n",
      "         2.0       0.98      0.65      0.78        95\n",
      "         3.0       0.93      1.00      0.96        74\n",
      "         4.0       0.84      0.89      0.86       100\n",
      "         5.0       0.97      0.93      0.95        90\n",
      "\n",
      "    accuracy                           0.92       780\n",
      "   macro avg       0.93      0.90      0.91       780\n",
      "weighted avg       0.93      0.92      0.92       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_deconf.reshape(-1), Y_pred_deconf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 16  800         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 16)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 32)   12832       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 64)  0           ['conv2d_6[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 16, 16, 1)   0           ['input_2[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 64)   0           ['average_pooling2d_2[0][0]',    \n",
      "                                                                  'average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 16)   1040        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4096)         0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4096)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           262208      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           4160        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           2080        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 6)            198         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,814\n",
      "Trainable params: 301,814\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_Y_oh_conf = to_categorical(train_Y_conf, num_classes=6)\n",
    "val_Y_oh_conf = to_categorical(val_Y_conf.reshape(-1), num_classes=6)\n",
    "\n",
    "model_conf = resNetCNN_model((128, 128, 1), n_class)\n",
    "model_conf.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model_conf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "950/950 [==============================] - 5s 4ms/step - loss: 1.0512 - accuracy: 0.5869 - val_loss: 0.3319 - val_accuracy: 0.8744\n",
      "Epoch 2/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.3924 - accuracy: 0.8594 - val_loss: 0.1742 - val_accuracy: 0.9502\n",
      "Epoch 3/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.2497 - accuracy: 0.9171 - val_loss: 0.1356 - val_accuracy: 0.9645\n",
      "Epoch 4/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1898 - accuracy: 0.9418 - val_loss: 0.1333 - val_accuracy: 0.9668\n",
      "Epoch 5/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1498 - accuracy: 0.9513 - val_loss: 0.0564 - val_accuracy: 0.9858\n",
      "Epoch 6/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.1145 - accuracy: 0.9616 - val_loss: 0.0911 - val_accuracy: 0.9692\n",
      "Epoch 7/75\n",
      "950/950 [==============================] - 5s 5ms/step - loss: 0.1292 - accuracy: 0.9634 - val_loss: 0.0669 - val_accuracy: 0.9763\n",
      "Epoch 8/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.0836 - val_accuracy: 0.9763\n",
      "Epoch 9/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.0776 - val_accuracy: 0.9834\n",
      "Epoch 10/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0700 - accuracy: 0.9768 - val_loss: 0.0763 - val_accuracy: 0.9858\n",
      "Epoch 11/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.0442 - val_accuracy: 0.9905\n",
      "Epoch 12/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0754 - accuracy: 0.9771 - val_loss: 0.0594 - val_accuracy: 0.9882\n",
      "Epoch 13/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0654 - accuracy: 0.9805 - val_loss: 0.0517 - val_accuracy: 0.9858\n",
      "Epoch 14/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.1694 - val_accuracy: 0.9621\n",
      "Epoch 15/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 0.0518 - val_accuracy: 0.9834\n",
      "Epoch 16/75\n",
      "950/950 [==============================] - 5s 5ms/step - loss: 0.0501 - accuracy: 0.9824 - val_loss: 0.0598 - val_accuracy: 0.9929\n",
      "Epoch 17/75\n",
      "950/950 [==============================] - 5s 5ms/step - loss: 0.0509 - accuracy: 0.9853 - val_loss: 0.0516 - val_accuracy: 0.9929\n",
      "Epoch 18/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0729 - val_accuracy: 0.9905\n",
      "Epoch 19/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0488 - val_accuracy: 0.9929\n",
      "Epoch 20/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.0768 - val_accuracy: 0.9787\n",
      "Epoch 21/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0392 - accuracy: 0.9863 - val_loss: 0.0542 - val_accuracy: 0.9929\n",
      "Epoch 22/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0455 - accuracy: 0.9892 - val_loss: 0.0722 - val_accuracy: 0.9834\n",
      "Epoch 23/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.0374 - val_accuracy: 0.9953\n",
      "Epoch 24/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.0550 - val_accuracy: 0.9929\n",
      "Epoch 25/75\n",
      "950/950 [==============================] - 4s 4ms/step - loss: 0.0567 - accuracy: 0.9850 - val_loss: 0.0570 - val_accuracy: 0.9882\n",
      "Epoch 26/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0296 - accuracy: 0.9945 - val_loss: 0.0803 - val_accuracy: 0.9905\n",
      "Epoch 27/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0290 - accuracy: 0.9929 - val_loss: 0.0994 - val_accuracy: 0.9882\n",
      "Epoch 28/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 0.0864 - val_accuracy: 0.9858\n",
      "Epoch 29/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0331 - accuracy: 0.9908 - val_loss: 0.0710 - val_accuracy: 0.9882\n",
      "Epoch 30/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.1285 - val_accuracy: 0.9858\n",
      "Epoch 31/75\n",
      "950/950 [==============================] - 4s 5ms/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 0.0616 - val_accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b6717b460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=8, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "model_conf.fit(train_X_conf.reshape(-1, 128, 128, 1), train_Y_oh_conf, \n",
    "                epochs=75, batch_size=4, shuffle=True,\n",
    "                validation_data=(val_X_conf.reshape(-1, 128, 128, 1), val_Y_oh_conf),\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "132/132 [==============================] - 1s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_conf_train = model_conf.predict(trainVal_X_conf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_conf_test = model_conf.predict(test_X_conf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_deconf_train = model_conf.predict(trainVal_X_deconf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_deconf_test = model_conf.predict(test_X_deconf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_conf_train = np.argmax(Y_pred_conf_train, axis=1)  \n",
    "Y_pred_conf_test = np.argmax(Y_pred_conf_test, axis=1)\n",
    "Y_pred_deconf_train = np.argmax(Y_pred_deconf_train, axis=1)\n",
    "Y_pred_deconf_test = np.argmax(Y_pred_deconf_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on confounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       152\n",
      "           1       1.00      1.00      1.00       269\n",
      "           2       0.97      0.79      0.87        95\n",
      "           3       0.79      1.00      0.88        74\n",
      "           4       0.89      0.88      0.88       100\n",
      "           5       0.99      0.91      0.95        90\n",
      "\n",
      "    accuracy                           0.94       780\n",
      "   macro avg       0.93      0.92      0.92       780\n",
      "weighted avg       0.95      0.94      0.94       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_conf.reshape(-1), Y_pred_conf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on deconfounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91       152\n",
      "         1.0       0.93      0.39      0.55       269\n",
      "         2.0       0.27      0.66      0.39        95\n",
      "         3.0       0.72      0.46      0.56        74\n",
      "         4.0       0.73      0.87      0.79       100\n",
      "         5.0       0.65      0.87      0.74        90\n",
      "\n",
      "    accuracy                           0.65       780\n",
      "   macro avg       0.70      0.69      0.66       780\n",
      "weighted avg       0.77      0.65      0.65       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_deconf.reshape(-1), Y_pred_deconf_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
