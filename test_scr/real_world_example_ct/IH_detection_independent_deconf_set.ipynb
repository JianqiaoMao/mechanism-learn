{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import causalBootstrapping as cb\n",
    "from distEst_lib import MultivarContiDistributionEstimator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import tensorflow as tf\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "rng_bootstrap = np.random.RandomState(42)\n",
    "rng_train_test = np.random.RandomState(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_read(dir_list, img_size):\n",
    "    img_list = []\n",
    "    for dir in dir_list:\n",
    "        img = cv2.imread(dir, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img_list.append(img.flatten())\n",
    "    return np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/Happiness_source/PhD/UoB/projects/Mechanism Learning/code/dataset/ICH_data/\"\n",
    "effect_dir = dir + \"data/image_clean/\"\n",
    "mediator_dir = dir + \"data/\"\n",
    "cause_dir = dir\n",
    "imgs_names = os.listdir(effect_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_imgs = img_read([effect_dir + img_name for img_name in imgs_names], (128, 128))\n",
    "cause_table = pd.read_csv(cause_dir + \"hemorrhage_diagnosis_ct_clean.csv\")\n",
    "mediator_table = pd.read_csv(mediator_dir + \"mediator_embedding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cause Var Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"No Hemorrhage\", 1: \"Intraventricular\", 2: \"Intraparenchymal\", 3: \"Subarachnoid\", 4: \"Epidural\", 5: \"Subdural\"}\n",
    "\n",
    "cause_table[\"category\"] = np.nan\n",
    "cause_table.loc[cause_table[\"No_Hemorrhage\"] == 1, \"category\"] = 0\n",
    "cause_table.loc[cause_table[\"Intraventricular\"] == 1, \"category\"] = 1\n",
    "cause_table.loc[cause_table[\"Intraparenchymal\"] == 1, \"category\"] = 2\n",
    "cause_table.loc[cause_table[\"Subarachnoid\"] == 1, \"category\"] = 3\n",
    "cause_table.loc[cause_table[\"Epidural\"] == 1, \"category\"] = 4\n",
    "cause_table.loc[cause_table[\"Subdural\"] == 1, \"category\"] = 5\n",
    "cause_table[\"category\"] = cause_table[\"category\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_category = cause_table[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(cause_table[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediator Var Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.445242</td>\n",
       "      <td>11.299638</td>\n",
       "      <td>8.707513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.309047</td>\n",
       "      <td>7.546306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.398108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.386361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2    3         4         5    6          7  \\\n",
       "0  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "1  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "2  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "3  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "4  7.445242  11.299638  8.707513  0.0  3.309047  7.546306  0.0  10.398108   \n",
       "\n",
       "     8          9  \n",
       "0  0.0  12.386361  \n",
       "1  0.0  12.386361  \n",
       "2  0.0  12.386361  \n",
       "3  0.0  12.386361  \n",
       "4  0.0  12.386361  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediator_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3\n",
       "0.0    2411\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediator_table['3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the all-zero column\n",
    "mediator_table.drop(columns=['3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format variables and normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_imgs = effect_imgs/255.0\n",
    "cause_category = cause_category.reshape(-1,1)\n",
    "mediaor_values = mediator_table.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate required distributions for causal bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cause_data = {\"Y\": cause_category}\n",
    "mediator_data = {\"Z\": mediaor_values}\n",
    "effect_data = {\"X\": effect_imgs} \n",
    "n_bins_yz = [0]+[6 for i in range(mediaor_values.shape[1])]\n",
    "n_bins_y = [0]\n",
    "\n",
    "joint_yz_data = np.concatenate((cause_category, mediaor_values), axis = 1)\n",
    "\n",
    "dist_estimator_yz = MultivarContiDistributionEstimator(data_fit=joint_yz_data, n_bins = n_bins_yz)\n",
    "pdf_yz, pyz = dist_estimator_yz.fit_histogram()\n",
    "dist_estimator_y = MultivarContiDistributionEstimator(data_fit=cause_category, n_bins = n_bins_y)\n",
    "pdf_y, py = dist_estimator_y.fit_histogram()\n",
    "\n",
    "dist_map = {\"Y,Z\": lambda Y, Z: pdf_yz([Y,Z]),\n",
    "            \"Y',Z\": lambda Y_prime, Z: pdf_yz([Y_prime,Z]),\n",
    "            \"Y\": lambda Y: pdf_y(Y),\n",
    "            \"Y'\": lambda Y_prime: pdf_y(Y_prime)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare inputs for causal bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interventional prob.:p_{Y}(X)=\\sum_{Y',Z}[p(X|Y',Z)p(Z|Y)p(Y')]\n",
      "Causal bootstrapping weights function: [P(Y,Z)P(Y')]/N*[P(Y)P(Y',Z)]\n",
      "Required distributions:\n",
      "1: P(Y,Z)\n",
      "2: P(Y')\n",
      "3: P(Y)\n",
      "4: P(Y',Z)\n"
     ]
    }
   ],
   "source": [
    "causal_graph = '\"Front-door\"; \\\n",
    "                Y; X; Z; \\\n",
    "                Y -> Z; \\\n",
    "                Z -> X; \\\n",
    "                X <-> Y;'\n",
    "weight_func_lam, weight_func_str = cb.general_cb_analysis(causal_graph = causal_graph, \n",
    "                                                          effect_var_name = 'X', \n",
    "                                                          cause_var_name = 'Y',\n",
    "                                                          info_print = True)\n",
    "N = cause_category.shape[0]\n",
    "w_func = weight_func_lam(dist_map = dist_map, N = N, kernel = None)\n",
    "cause_var_name = list(cause_data.keys())[0]\n",
    "effect_var_name = list(effect_data.keys())[0]\n",
    "mediator_var_name = list(mediator_data.keys())[0]\n",
    "\n",
    "data = {cause_var_name+\"'\": list(cause_data.values())[0]}\n",
    "data.update(effect_data)\n",
    "data.update(mediator_data)\n",
    "n_sample = [1000, 800, 800, 800, 800, 800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training and test datasets by identifying the causal bootstrap indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVal_X_deconf = np.empty((0, effect_imgs.shape[1]))\n",
    "trainVal_Y_deconf = np.empty((0, 1))\n",
    "test_X_deconf = np.empty((0, effect_imgs.shape[1]))\n",
    "test_Y_deconf = np.empty((0, 1))\n",
    "\n",
    "trainVal_X_conf = np.empty((0, effect_imgs.shape[1]))\n",
    "trainVal_Y_conf = np.empty((0, 1))\n",
    "test_X_conf = np.empty((0, effect_imgs.shape[1]))\n",
    "test_Y_conf = np.empty((0, 1))\n",
    "\n",
    "train_size = 0.85\n",
    "weights = np.empty((n_class, N))\n",
    "idx_ib_by_class = []\n",
    "idx_ib_all_unique = []\n",
    "for class_i in range(n_class):\n",
    "    weights_itv = cb.weight_compute(w_func, data, intv_var = {\"Y\":[class_i for i in range(N)]})\n",
    "    weights[class_i] = weights_itv\n",
    "    weights_norm = weights_itv/np.sum(weights_itv)\n",
    "    idx_ib = rng_bootstrap.choice(range(N), size = n_sample[class_i], replace = True, p = weights_norm)\n",
    "    idx_ib_by_class.append(list(idx_ib))\n",
    "    idx_ib_unique = np.unique(idx_ib)\n",
    "    idx_ib_all_unique.append(idx_ib_unique)\n",
    "idx_ib_all_unique = np.unique(np.concatenate(idx_ib_all_unique))\n",
    "idx_ib_train = rng_train_test.choice(idx_ib_all_unique, size = int(train_size*idx_ib_all_unique.shape[0]), replace = False)\n",
    "idx_ib_test = np.setdiff1d(idx_ib_all_unique, idx_ib_train)\n",
    "idx_all_test = np.setdiff1d(range(N), idx_ib_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_i in range(n_class):\n",
    "    idx_ib_train_bootstrap = [idx for idx in idx_ib_by_class[class_i] if idx in idx_ib_train]\n",
    "    trainVal_X_deconf = np.concatenate((trainVal_X_deconf, effect_imgs[idx_ib_train_bootstrap, :]), axis = 0)\n",
    "    trainVal_Y_deconf = np.concatenate((trainVal_Y_deconf, np.array([class_i for i in range(len(idx_ib_train_bootstrap))]).reshape(-1,1)), axis = 0)\n",
    "    \n",
    "    idx_ib_test_bootstrap = [idx for idx in idx_ib_by_class[class_i] if idx in idx_ib_test]\n",
    "    test_X_deconf = np.concatenate((test_X_deconf, effect_imgs[idx_ib_test_bootstrap, :]), axis = 0)\n",
    "    test_Y_deconf = np.concatenate((test_Y_deconf, np.array([class_i for i in range(len(idx_ib_test_bootstrap))]).reshape(-1,1)), axis = 0)\n",
    "    \n",
    "trainVal_X_conf = effect_imgs[idx_ib_train, :]\n",
    "trainVal_Y_conf = cause_category[idx_ib_train].reshape(-1,1)\n",
    "test_X_conf = effect_imgs[idx_all_test, :]\n",
    "test_Y_conf = cause_category[idx_all_test].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample the confounded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training set\n",
    "n_rus_train = [np.min([trainVal_Y_deconf[trainVal_Y_deconf == i].shape[0],trainVal_Y_conf[trainVal_Y_conf == i].shape[0]]) for i in range(n_class)]\n",
    "rus_train = RandomUnderSampler(sampling_strategy={i: n_rus_train[i] for i in range(n_class)}, random_state = 42)\n",
    "trainVal_X_conf, trainVal_Y_conf = rus_train.fit_resample(trainVal_X_conf, trainVal_Y_conf)\n",
    "\n",
    "n_ros_train = [trainVal_Y_deconf[trainVal_Y_deconf == i].shape[0] for i in range(n_class)]\n",
    "ros_train = RandomOverSampler(sampling_strategy = {i: n_ros_train[i] for i in range(n_class)}, random_state = 42)\n",
    "trainVal_X_conf, trainVal_Y_conf = ros_train.fit_resample(trainVal_X_conf, trainVal_Y_conf)\n",
    "\n",
    "# Resample the test set\n",
    "n_rus_test = [np.min([test_Y_deconf[test_Y_deconf == i].shape[0],test_Y_conf[test_Y_conf == i].shape[0]]) for i in range(6)]\n",
    "rus_test = RandomUnderSampler(sampling_strategy={i: n_rus_test[i] for i in range(n_class)}, random_state = 42)\n",
    "test_X_conf, test_Y_conf = rus_test.fit_resample(test_X_conf, test_Y_conf)\n",
    "\n",
    "n_ros_test = [test_Y_deconf[test_Y_deconf == i].shape[0] for i in range(n_class)]\n",
    "ros_test = RandomOverSampler(sampling_strategy = {i: n_ros_test[i] for i in range(n_class)}, random_state = 42)\n",
    "test_X_conf, test_Y_conf = ros_test.fit_resample(test_X_conf, test_Y_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the validation set for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconfounded data split\n",
    "val_size = 0.1\n",
    "train_X_deconf, val_X_deconf, train_Y_deconf, val_Y_deconf = train_test_split(trainVal_X_deconf, trainVal_Y_deconf, \n",
    "                                                                              test_size=val_size, stratify=trainVal_Y_deconf, random_state=17)\n",
    "# Confounded data split\n",
    "train_X_conf, val_X_conf, train_Y_conf, val_Y_conf = train_test_split(trainVal_X_conf, trainVal_Y_conf,\n",
    "                                                                      test_size=val_size, stratify=trainVal_Y_conf, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 16  800         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 32)   12832       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 64)  0           ['conv2d_2[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 1)   0           ['input_1[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 64)   0           ['average_pooling2d[0][0]',      \n",
      "                                                                  'average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 16)   1040        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           262208      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 6)            198         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,814\n",
      "Trainable params: 301,814\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def resNetCNN_model(input_shape, num_class):\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    short_cut = input_img\n",
    "    x = layers.Conv2D(16, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.AveragePooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    short_cut = layers.AveragePooling2D((8, 8), padding='same')(short_cut)\n",
    "    x = layers.Add()([x, short_cut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, (1, 1), activation='relu', padding='same')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    encoded = layers.Dense(num_class, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(input_img, encoded)\n",
    "\n",
    "model_deconf = resNetCNN_model((128, 128, 1), n_class)\n",
    "model_deconf.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model_deconf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the deconfounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "950/950 [==============================] - 34s 32ms/step - loss: 1.1970 - accuracy: 0.5358 - val_loss: 0.6635 - val_accuracy: 0.7725\n",
      "Epoch 2/75\n",
      "950/950 [==============================] - 30s 31ms/step - loss: 0.6482 - accuracy: 0.7657 - val_loss: 0.4245 - val_accuracy: 0.8815\n",
      "Epoch 3/75\n",
      "950/950 [==============================] - 31s 33ms/step - loss: 0.4770 - accuracy: 0.8310 - val_loss: 0.4094 - val_accuracy: 0.8934\n",
      "Epoch 4/75\n",
      "950/950 [==============================] - 31s 32ms/step - loss: 0.3857 - accuracy: 0.8697 - val_loss: 0.2502 - val_accuracy: 0.9123\n",
      "Epoch 5/75\n",
      "950/950 [==============================] - 30s 32ms/step - loss: 0.3345 - accuracy: 0.8928 - val_loss: 0.1953 - val_accuracy: 0.9289\n",
      "Epoch 6/75\n",
      "950/950 [==============================] - 31s 33ms/step - loss: 0.3091 - accuracy: 0.8968 - val_loss: 0.2118 - val_accuracy: 0.9242\n",
      "Epoch 7/75\n",
      "950/950 [==============================] - 31s 33ms/step - loss: 0.2806 - accuracy: 0.9071 - val_loss: 0.2260 - val_accuracy: 0.9194\n",
      "Epoch 8/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.2618 - accuracy: 0.9205 - val_loss: 0.2521 - val_accuracy: 0.9171\n",
      "Epoch 9/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.2463 - accuracy: 0.9258 - val_loss: 0.2290 - val_accuracy: 0.9147\n",
      "Epoch 10/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.2290 - accuracy: 0.9210 - val_loss: 0.2078 - val_accuracy: 0.9313\n",
      "Epoch 11/75\n",
      "950/950 [==============================] - 35s 36ms/step - loss: 0.2103 - accuracy: 0.9289 - val_loss: 0.2219 - val_accuracy: 0.9289\n",
      "Epoch 12/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1954 - accuracy: 0.9360 - val_loss: 0.1775 - val_accuracy: 0.9360\n",
      "Epoch 13/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.1907 - accuracy: 0.9394 - val_loss: 0.1908 - val_accuracy: 0.9313\n",
      "Epoch 14/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.2024 - accuracy: 0.9379 - val_loss: 0.2212 - val_accuracy: 0.9360\n",
      "Epoch 15/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1976 - accuracy: 0.9344 - val_loss: 0.1826 - val_accuracy: 0.9265\n",
      "Epoch 16/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1787 - accuracy: 0.9405 - val_loss: 0.1961 - val_accuracy: 0.9408\n",
      "Epoch 17/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1888 - accuracy: 0.9400 - val_loss: 0.1980 - val_accuracy: 0.9384\n",
      "Epoch 18/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1809 - accuracy: 0.9418 - val_loss: 0.2641 - val_accuracy: 0.9242\n",
      "Epoch 19/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1658 - accuracy: 0.9484 - val_loss: 0.1772 - val_accuracy: 0.9408\n",
      "Epoch 20/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.1906 - accuracy: 0.9413 - val_loss: 0.1931 - val_accuracy: 0.9313\n",
      "Epoch 21/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1590 - accuracy: 0.9494 - val_loss: 0.1695 - val_accuracy: 0.9408\n",
      "Epoch 22/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1627 - accuracy: 0.9516 - val_loss: 0.2262 - val_accuracy: 0.9431\n",
      "Epoch 23/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1643 - accuracy: 0.9463 - val_loss: 0.1749 - val_accuracy: 0.9384\n",
      "Epoch 24/75\n",
      "950/950 [==============================] - 38s 40ms/step - loss: 0.1554 - accuracy: 0.9476 - val_loss: 0.1903 - val_accuracy: 0.9431\n",
      "Epoch 25/75\n",
      "950/950 [==============================] - 35s 36ms/step - loss: 0.1684 - accuracy: 0.9487 - val_loss: 0.1712 - val_accuracy: 0.9431\n",
      "Epoch 26/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1561 - accuracy: 0.9518 - val_loss: 0.1822 - val_accuracy: 0.9431\n",
      "Epoch 27/75\n",
      "950/950 [==============================] - 34s 35ms/step - loss: 0.1690 - accuracy: 0.9466 - val_loss: 0.2624 - val_accuracy: 0.9360\n",
      "Epoch 28/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1470 - accuracy: 0.9531 - val_loss: 0.1690 - val_accuracy: 0.9455\n",
      "Epoch 29/75\n",
      "950/950 [==============================] - 33s 34ms/step - loss: 0.1520 - accuracy: 0.9502 - val_loss: 0.1821 - val_accuracy: 0.9479\n",
      "Epoch 30/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1464 - accuracy: 0.9534 - val_loss: 0.1921 - val_accuracy: 0.9360\n",
      "Epoch 31/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.1510 - accuracy: 0.9494 - val_loss: 0.2081 - val_accuracy: 0.9384\n",
      "Epoch 32/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.1591 - accuracy: 0.9500 - val_loss: 0.1853 - val_accuracy: 0.9384\n",
      "Epoch 33/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1467 - accuracy: 0.9518 - val_loss: 0.2926 - val_accuracy: 0.9360\n",
      "Epoch 34/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.1473 - accuracy: 0.9552 - val_loss: 0.1495 - val_accuracy: 0.9479\n",
      "Epoch 35/75\n",
      "950/950 [==============================] - 31s 33ms/step - loss: 0.1367 - accuracy: 0.9531 - val_loss: 0.1618 - val_accuracy: 0.9384\n",
      "Epoch 36/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1632 - accuracy: 0.9479 - val_loss: 0.2000 - val_accuracy: 0.9360\n",
      "Epoch 37/75\n",
      "950/950 [==============================] - 31s 32ms/step - loss: 0.1335 - accuracy: 0.9563 - val_loss: 0.1656 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e70ea27400>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_deconf_oh = to_categorical(train_Y_deconf.reshape(-1), num_classes=6)\n",
    "val_Y_deconf_oh = to_categorical(val_Y_deconf.reshape(-1), num_classes=6)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=8, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True, start_from_epoch = 5)\n",
    "\n",
    "model_deconf.fit(train_X_deconf.reshape(-1, 128, 128, 1), train_Y_deconf_oh, \n",
    "                 epochs=75, batch_size=4, shuffle=True,\n",
    "                 validation_data=(val_X_deconf.reshape(-1, 128, 128, 1), val_Y_deconf_oh),\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 5s 34ms/step\n",
      "25/25 [==============================] - 1s 34ms/step\n",
      "132/132 [==============================] - 5s 39ms/step\n",
      "25/25 [==============================] - 1s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_conf_train = model_deconf.predict(trainVal_X_conf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_conf_test = model_deconf.predict(test_X_conf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_deconf_train = model_deconf.predict(trainVal_X_deconf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_deconf_test = model_deconf.predict(test_X_deconf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_conf_train = np.argmax(Y_pred_conf_train, axis=1)\n",
    "Y_pred_conf_test = np.argmax(Y_pred_conf_test, axis=1)\n",
    "Y_pred_deconf_train = np.argmax(Y_pred_deconf_train, axis=1)\n",
    "Y_pred_deconf_test = np.argmax(Y_pred_deconf_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on confounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       152\n",
      "           1       0.97      1.00      0.99       269\n",
      "           2       1.00      0.59      0.74        95\n",
      "           3       0.54      0.51      0.53        74\n",
      "           4       0.98      0.88      0.93       100\n",
      "           5       0.70      1.00      0.83        90\n",
      "\n",
      "    accuracy                           0.88       780\n",
      "   macro avg       0.85      0.83      0.83       780\n",
      "weighted avg       0.90      0.88      0.88       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_conf.reshape(-1), Y_pred_conf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on deconfounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       152\n",
      "         1.0       0.92      1.00      0.96       269\n",
      "         2.0       1.00      0.39      0.56        95\n",
      "         3.0       0.44      0.27      0.34        74\n",
      "         4.0       0.86      0.87      0.87       100\n",
      "         5.0       0.60      1.00      0.75        90\n",
      "\n",
      "    accuracy                           0.83       780\n",
      "   macro avg       0.79      0.75      0.73       780\n",
      "weighted avg       0.84      0.83      0.81       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_deconf.reshape(-1), Y_pred_deconf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 16  800         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 16)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 32)   12832       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 64)  0           ['conv2d_6[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 16, 16, 1)   0           ['input_2[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 64)   0           ['average_pooling2d_2[0][0]',    \n",
      "                                                                  'average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 16)   1040        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4096)         0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4096)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           262208      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           4160        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           2080        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 6)            198         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,814\n",
      "Trainable params: 301,814\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_Y_oh_conf = to_categorical(train_Y_conf, num_classes=6)\n",
    "val_Y_oh_conf = to_categorical(val_Y_conf.reshape(-1), num_classes=6)\n",
    "\n",
    "model_conf = resNetCNN_model((128, 128, 1), n_class)\n",
    "model_conf.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model_conf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the confounded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "950/950 [==============================] - 35s 35ms/step - loss: 1.0407 - accuracy: 0.5887 - val_loss: 0.3043 - val_accuracy: 0.8886\n",
      "Epoch 2/75\n",
      "950/950 [==============================] - 32s 33ms/step - loss: 0.3373 - accuracy: 0.8834 - val_loss: 0.1659 - val_accuracy: 0.9526\n",
      "Epoch 3/75\n",
      "950/950 [==============================] - 33s 34ms/step - loss: 0.2207 - accuracy: 0.9284 - val_loss: 0.1170 - val_accuracy: 0.9692\n",
      "Epoch 4/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1561 - accuracy: 0.9516 - val_loss: 0.0881 - val_accuracy: 0.9787\n",
      "Epoch 5/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1206 - accuracy: 0.9592 - val_loss: 0.0743 - val_accuracy: 0.9834\n",
      "Epoch 6/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.0938 - accuracy: 0.9697 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 7/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.0974 - accuracy: 0.9716 - val_loss: 0.0573 - val_accuracy: 0.9905\n",
      "Epoch 8/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.1111 - accuracy: 0.9642 - val_loss: 0.0667 - val_accuracy: 0.9905\n",
      "Epoch 9/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.0663 - val_accuracy: 0.9858\n",
      "Epoch 10/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.0654 - accuracy: 0.9789 - val_loss: 0.0647 - val_accuracy: 0.9905\n",
      "Epoch 11/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0622 - val_accuracy: 0.9882\n",
      "Epoch 12/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.0638 - accuracy: 0.9803 - val_loss: 0.0756 - val_accuracy: 0.9882\n",
      "Epoch 13/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.0484 - accuracy: 0.9868 - val_loss: 0.0806 - val_accuracy: 0.9810\n",
      "Epoch 14/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.0788 - val_accuracy: 0.9858\n",
      "Epoch 15/75\n",
      "950/950 [==============================] - 34s 36ms/step - loss: 0.0479 - accuracy: 0.9879 - val_loss: 0.0549 - val_accuracy: 0.9929\n",
      "Epoch 16/75\n",
      "950/950 [==============================] - 35s 36ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 0.0476 - val_accuracy: 0.9953\n",
      "Epoch 17/75\n",
      "950/950 [==============================] - 33s 34ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 0.0661 - val_accuracy: 0.9929\n",
      "Epoch 18/75\n",
      "950/950 [==============================] - 33s 35ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 0.0568 - val_accuracy: 0.9953\n",
      "Epoch 19/75\n",
      "950/950 [==============================] - 36s 38ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0412 - val_accuracy: 0.9953\n",
      "Epoch 20/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.0812 - val_accuracy: 0.9905\n",
      "Epoch 21/75\n",
      "950/950 [==============================] - 35s 37ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.0395 - val_accuracy: 0.9929\n",
      "Epoch 22/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0555 - val_accuracy: 0.9929\n",
      "Epoch 23/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.0788 - val_accuracy: 0.9858\n",
      "Epoch 24/75\n",
      "950/950 [==============================] - 32s 34ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0468 - val_accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e70f7f3670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=8, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True, start_from_epoch = 5)\n",
    "\n",
    "model_conf.fit(train_X_conf.reshape(-1, 128, 128, 1), train_Y_oh_conf, \n",
    "                epochs=75, batch_size=4, shuffle=True,\n",
    "                validation_data=(val_X_conf.reshape(-1, 128, 128, 1), val_Y_oh_conf),\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 4s 32ms/step\n",
      "25/25 [==============================] - 1s 34ms/step\n",
      "132/132 [==============================] - 5s 35ms/step\n",
      "25/25 [==============================] - 1s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_conf_train = model_conf.predict(trainVal_X_conf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_conf_test = model_conf.predict(test_X_conf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_deconf_train = model_conf.predict(trainVal_X_deconf.reshape(-1, 128, 128, 1))\n",
    "Y_pred_deconf_test = model_conf.predict(test_X_deconf.reshape(-1, 128, 128, 1))\n",
    "\n",
    "Y_pred_conf_train = np.argmax(Y_pred_conf_train, axis=1)  \n",
    "Y_pred_conf_test = np.argmax(Y_pred_conf_test, axis=1)\n",
    "Y_pred_deconf_train = np.argmax(Y_pred_deconf_train, axis=1)\n",
    "Y_pred_deconf_test = np.argmax(Y_pred_deconf_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on confounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       152\n",
      "           1       1.00      1.00      1.00       269\n",
      "           2       0.97      0.66      0.79        95\n",
      "           3       0.70      1.00      0.82        74\n",
      "           4       0.97      0.94      0.95       100\n",
      "           5       0.97      1.00      0.98        90\n",
      "\n",
      "    accuracy                           0.94       780\n",
      "   macro avg       0.93      0.93      0.92       780\n",
      "weighted avg       0.95      0.94      0.94       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_conf.reshape(-1), Y_pred_conf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on deconfounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94       152\n",
      "         1.0       0.93      0.39      0.55       269\n",
      "         2.0       0.24      0.54      0.33        95\n",
      "         3.0       0.58      0.46      0.51        74\n",
      "         4.0       0.85      0.94      0.90       100\n",
      "         5.0       0.67      1.00      0.80        90\n",
      "\n",
      "    accuracy                           0.66       780\n",
      "   macro avg       0.70      0.71      0.67       780\n",
      "weighted avg       0.78      0.66      0.67       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y_deconf.reshape(-1), Y_pred_deconf_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
