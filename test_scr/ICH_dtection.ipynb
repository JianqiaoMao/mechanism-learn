{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d7ccbb",
   "metadata": {},
   "source": [
    "## The experiment on real-world ICH detection using mechanism learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d80357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mechanism_learn import pipeline as mlpipe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os \n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gc\n",
    "\n",
    "def img_read(dir_list, img_size):\n",
    "    img_list = []\n",
    "    for dir in dir_list:\n",
    "        img = cv2.imread(dir, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img_list.append(img.flatten())\n",
    "    return np.array(img_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9b6e5",
   "metadata": {},
   "source": [
    "### Setup the GPU to accelerate the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fea811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Built with CUDA?: True\n",
      "Built with GPU?: True\n",
      "Available GPU device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA?:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU?:\", tf.test.is_built_with_gpu_support())\n",
    "print(\"Available GPU device:\", tf.config.list_physical_devices('GPU'))\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72382281",
   "metadata": {},
   "source": [
    "### ResNet-CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cb8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resNetCNN_model(input_shape, num_class):\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    short_cut = input_img\n",
    "    x = layers.Conv2D(16, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.AveragePooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    short_cut = layers.AveragePooling2D((8, 8), padding='same')(short_cut)\n",
    "    x = layers.Add()([x, short_cut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, (1, 1), activation='relu', padding='same')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    encoded = layers.Dense(num_class, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8702724",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5600d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"../test_data/ICH_data/\"\n",
    "effect_dir = dir + r\"ct_clean/\"\n",
    "mediator_dir = dir\n",
    "cause_dir = dir\n",
    "imgs_names = os.listdir(effect_dir)\n",
    "imgs_names = sorted(imgs_names, key=lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bdf8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_imgs = img_read([effect_dir + img_name for img_name in imgs_names], (128, 128))\n",
    "cause_table = pd.read_csv(cause_dir + \"hemorrhage_diagnosis_ct_clean.csv\")\n",
    "mediator_table = pd.read_csv(mediator_dir + \"mediator_embedding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e878c",
   "metadata": {},
   "source": [
    "### Cause variable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb2df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cause_table[\"category\"] = np.nan\n",
    "cause_table.loc[cause_table[\"No_Hemorrhage\"] == 1, \"category\"] = 0\n",
    "cause_table.loc[cause_table[\"Intraparenchymal\"] == 1, \"category\"] = 1\n",
    "cause_table.loc[cause_table[\"Epidural\"] == 1, \"category\"] = 2\n",
    "cause_table.loc[cause_table[\"Subdural\"] == 1, \"category\"] = 3\n",
    "cause_table.loc[cause_table[\"Intraventricular\"] == 1, \"category\"] = 4\n",
    "cause_table.loc[cause_table[\"Subarachnoid\"] == 1, \"category\"] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8afac8",
   "metadata": {},
   "source": [
    "### Mediator variable cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9dad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "1924dec6-a280-46ba-839c-0cd075368768",
       "rows": [
        [
         "0",
         "False"
        ],
        [
         "1",
         "False"
        ],
        [
         "2",
         "False"
        ],
        [
         "3",
         "True"
        ],
        [
         "4",
         "False"
        ],
        [
         "5",
         "False"
        ],
        [
         "6",
         "False"
        ],
        [
         "7",
         "False"
        ],
        [
         "8",
         "False"
        ],
        [
         "9",
         "False"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mediator_table == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eaeec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [0. 1. 2. 3. 4. 5.]\n",
      "Counts: [2093   52  171   56   21   18]\n"
     ]
    }
   ],
   "source": [
    "category_unique, category_cnt = np.unique(cause_table[\"category\"], return_counts=True)\n",
    "print(\"Categories:\", category_unique)\n",
    "print(\"Counts:\", category_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbddbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_table.drop(columns=['3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20552d",
   "metadata": {},
   "source": [
    "### Prepare the final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773227e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_category = cause_table[\"category\"].values\n",
    "cause_category = cause_category.reshape(-1,1)\n",
    "mediaor_values = mediator_table.values\n",
    "n_class = len(cause_table[\"category\"].unique())\n",
    "X_d = effect_imgs.shape[1]\n",
    "image_h = int(np.sqrt(X_d))\n",
    "image_w = int(np.sqrt(X_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14aa23",
   "metadata": {},
   "source": [
    "### Reduce the dimensionality of the effect variable using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502d6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Reduced dimension of effect images: 753\n"
     ]
    }
   ],
   "source": [
    "img_pca = PCA(n_components=0.95)\n",
    "img_pca.fit(effect_imgs)\n",
    "effect_imgs_lowd_embedding = img_pca.transform(effect_imgs)\n",
    "reduced_X_d = effect_imgs_lowd_embedding.shape[1]\n",
    "print(\"PCA Reduced dimension of effect images:\", reduced_X_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc7337",
   "metadata": {},
   "source": [
    "### Split training and test datasets for confounded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e640a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prop = 0.4\n",
    "X_train_conf, X_testval_conf, Y_train_conf, Y_testval_conf = train_test_split(effect_imgs, cause_category, \n",
    "                                                                             test_size=test_prop, random_state=42, stratify=cause_category)\n",
    "\n",
    "val_prop = 0.4\n",
    "X_val_conf, X_test_conf, Y_val_conf, Y_test_conf = train_test_split(X_testval_conf, Y_testval_conf,\n",
    "                                                                    test_size=1-val_prop, random_state=42, stratify=Y_testval_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e02b2",
   "metadata": {},
   "source": [
    "### Deconfounded ResNet-CNN using mechanism learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the machanism learning pipeline\n",
    "ml_gmm_pipeline = mlpipe.mechanism_learning_process(cause_data = cause_category,\n",
    "                                                    mechanism_data = mediaor_values, \n",
    "                                                    effect_data = effect_imgs_lowd_embedding, \n",
    "                                                    intv_values = np.unique(cause_category), \n",
    "                                                    dist_map = None, \n",
    "                                                    est_method = \"kde\",\n",
    "                                                    bandwidth = \"scott\"\n",
    "                                                    )\n",
    "\n",
    "# Fitting the CWGMM model\n",
    "## Don't sample the data, just fit and return the CWGMM model for later sampling\n",
    "## Set different comp_k for different intervention categories because of the class imbalance\n",
    "ml_gmm_pipeline.cwgmm_fit(comp_k = [400, 10, 55, 11, 4, 3],\n",
    "                          max_iter = 500, \n",
    "                          tol = 1e-5, \n",
    "                          init_method = \"kmeans++\", \n",
    "                          cov_type = \"diag\", \n",
    "                          random_seed = None, \n",
    "                          return_model = False,\n",
    "                          verbose = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081724e",
   "metadata": {},
   "source": [
    "#### Sample the deconfounded data (i.i.d) to form the deconfounded training, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e29c2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_sample = [5000 for i in range(len(np.unique(cause_category)))]\n",
    "n_val_sample = np.unique(Y_val_conf, return_counts=True)[1]\n",
    "n_test_sample = np.unique(Y_test_conf, return_counts=True)[1]\n",
    "\n",
    "# Sample the deconfounded training data\n",
    "X_train_deconf_gmm, Y_train_deconf_gmm = ml_gmm_pipeline.cwgmm_resample(n_samples=n_train_sample, return_samples = True)\n",
    "# Inverse transform the sampled image embedding to the original space\n",
    "X_train_deconf_gmm = img_pca.inverse_transform(X_train_deconf_gmm)\n",
    "# Clip the X values to be in the range of [0, 255] as the original images\n",
    "X_train_deconf_gmm = np.clip(X_train_deconf_gmm, 0, 255.0)\n",
    "# Reshape the data to the original image shape\n",
    "X_train_deconf_gmm = X_train_deconf_gmm.reshape(-1,image_h,image_w,1)\n",
    "\n",
    "X_val_deconf, Y_val_deconf = ml_gmm_pipeline.cwgmm_resample(n_samples=n_val_sample, return_samples = True)\n",
    "# Inverse transform the sampled image embedding to the original space\n",
    "X_val_deconf = img_pca.inverse_transform(X_val_deconf)\n",
    "# Clip the X values to be in the range of [0, 255] as the original images\n",
    "X_val_deconf = np.clip(X_val_deconf, 0, 255.0)\n",
    "# Reshape the data to the original image shape\n",
    "X_val_deconf = X_val_deconf.reshape(-1,image_h,image_w,1)\n",
    "\n",
    "X_test_deconf, Y_test_deconf = ml_gmm_pipeline.cwgmm_resample(n_samples=n_test_sample, return_samples = True)\n",
    "# Inverse transform the sampled image embedding to the original space\n",
    "X_test_deconf = img_pca.inverse_transform(X_test_deconf)\n",
    "# Clip the X values to be in the range of [0, 255] as the original images\n",
    "X_test_deconf = np.clip(X_test_deconf, 0, 255.0)\n",
    "# Reshape the data to the original image shape\n",
    "X_test_deconf = X_test_deconf.reshape(-1,image_h,image_w,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b37c3",
   "metadata": {},
   "source": [
    "#### Compile and train the mechanism learning-based deconfounded ResNet-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96127281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "7500/7500 [==============================] - 37s 4ms/step - loss: 1.0343 - accuracy: 0.6331 - val_loss: 0.9808 - val_accuracy: 0.6399\n",
      "Epoch 2/75\n",
      "7500/7500 [==============================] - 31s 4ms/step - loss: 0.5556 - accuracy: 0.8013 - val_loss: 0.6846 - val_accuracy: 0.7746\n",
      "Epoch 3/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.4023 - accuracy: 0.8647 - val_loss: 0.8731 - val_accuracy: 0.7358\n",
      "Epoch 4/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.3070 - accuracy: 0.9019 - val_loss: 0.3023 - val_accuracy: 0.9275\n",
      "Epoch 5/75\n",
      "7500/7500 [==============================] - 32s 4ms/step - loss: 0.2639 - accuracy: 0.9168 - val_loss: 0.4570 - val_accuracy: 0.8834\n",
      "Epoch 6/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2391 - accuracy: 0.9253 - val_loss: 0.2601 - val_accuracy: 0.9534\n",
      "Epoch 7/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.2206 - accuracy: 0.9351 - val_loss: 0.2269 - val_accuracy: 0.9378\n",
      "Epoch 8/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2052 - accuracy: 0.9409 - val_loss: 0.2337 - val_accuracy: 0.9378\n",
      "Epoch 9/75\n",
      "7500/7500 [==============================] - 41s 5ms/step - loss: 0.2156 - accuracy: 0.9394 - val_loss: 0.2757 - val_accuracy: 0.9249\n",
      "Epoch 10/75\n",
      "7500/7500 [==============================] - 48s 6ms/step - loss: 0.1899 - accuracy: 0.9454 - val_loss: 0.1789 - val_accuracy: 0.9741\n",
      "Epoch 11/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2151 - accuracy: 0.9401 - val_loss: 0.1386 - val_accuracy: 0.9741\n",
      "Epoch 12/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.1777 - accuracy: 0.9508 - val_loss: 0.1789 - val_accuracy: 0.9534\n",
      "Epoch 13/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.1807 - accuracy: 0.9511 - val_loss: 0.1302 - val_accuracy: 0.9585\n",
      "Epoch 14/75\n",
      "7500/7500 [==============================] - 40s 5ms/step - loss: 0.1902 - accuracy: 0.9504 - val_loss: 0.2575 - val_accuracy: 0.9585\n",
      "Epoch 15/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.1726 - accuracy: 0.9555 - val_loss: 0.1361 - val_accuracy: 0.9689\n",
      "Epoch 16/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2020 - accuracy: 0.9473 - val_loss: 0.2225 - val_accuracy: 0.9378\n",
      "Epoch 17/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.1946 - accuracy: 0.9531 - val_loss: 0.2184 - val_accuracy: 0.9508\n",
      "Epoch 18/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1865 - accuracy: 0.9511 - val_loss: 0.2325 - val_accuracy: 0.9534\n",
      "Epoch 19/75\n",
      "7500/7500 [==============================] - 34s 4ms/step - loss: 0.1746 - accuracy: 0.9570 - val_loss: 0.1665 - val_accuracy: 0.9741\n",
      "Epoch 20/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.1724 - accuracy: 0.9564 - val_loss: 0.1525 - val_accuracy: 0.9793\n",
      "Epoch 21/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.1642 - accuracy: 0.9582 - val_loss: 0.1843 - val_accuracy: 0.9585\n",
      "Epoch 22/75\n",
      "7500/7500 [==============================] - 34s 4ms/step - loss: 0.1698 - accuracy: 0.9556 - val_loss: 0.1059 - val_accuracy: 0.9793\n",
      "Epoch 23/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.1725 - accuracy: 0.9593 - val_loss: 0.2305 - val_accuracy: 0.9430\n",
      "Epoch 24/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1987 - accuracy: 0.9524 - val_loss: 0.1148 - val_accuracy: 0.9715\n",
      "Epoch 25/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1730 - accuracy: 0.9555 - val_loss: 0.3243 - val_accuracy: 0.9249\n",
      "Epoch 26/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.1886 - accuracy: 0.9552 - val_loss: 0.2988 - val_accuracy: 0.9456\n",
      "Epoch 27/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.1897 - accuracy: 0.9588 - val_loss: 0.2678 - val_accuracy: 0.9585\n",
      "Epoch 28/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.2192 - accuracy: 0.9493 - val_loss: 0.1563 - val_accuracy: 0.9637\n",
      "Epoch 29/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1906 - accuracy: 0.9544 - val_loss: 0.1888 - val_accuracy: 0.9663\n",
      "Epoch 30/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.2167 - accuracy: 0.9545 - val_loss: 0.2428 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25390a69d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet_gmm_deconf = resNetCNN_model((image_h, image_w, 1), n_class)\n",
    "ResNet_gmm_deconf.compile(optimizer='adam',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "Y_train_deconf_gmm_oh = to_categorical(Y_train_deconf_gmm.reshape(-1), num_classes=n_class)\n",
    "Y_val_deconf_oh = to_categorical(Y_val_deconf.reshape(-1), num_classes=n_class)\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=10, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "ResNet_gmm_deconf.fit(X_train_deconf_gmm, Y_train_deconf_gmm_oh, \n",
    "                      epochs=75, batch_size=4, shuffle=True,\n",
    "                      validation_data=(X_val_deconf, Y_val_deconf_oh),\n",
    "                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce53ec",
   "metadata": {},
   "source": [
    "#### Predict on synthetic \"non-confounded\" and confounded test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed27da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 6ms/step\n",
      "19/19 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_deconfModel_confTest_gmm = ResNet_gmm_deconf.predict(X_test_conf.reshape(-1, image_h, image_w, 1))\n",
    "Y_pred_deconfModel_deconfTest_gmm = ResNet_gmm_deconf.predict(X_test_deconf)\n",
    "Y_pred_deconfModel_confTest_gmm = np.argmax(Y_pred_deconfModel_confTest_gmm, axis=1)\n",
    "Y_pred_deconfModel_deconfTest_gmm = np.argmax(Y_pred_deconfModel_deconfTest_gmm, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b001b",
   "metadata": {},
   "source": [
    "#### Evaluate the model performance on confounded and synthetic \"non-confounded\" test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce0c7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9790    0.9264    0.9520       503\n",
      "         1.0     0.7273    0.6154    0.6667        13\n",
      "         2.0     0.5429    0.9268    0.6847        41\n",
      "         3.0     0.6667    0.7692    0.7143        13\n",
      "         4.0     1.0000    0.4000    0.5714         5\n",
      "         5.0     0.8000    1.0000    0.8889         4\n",
      "\n",
      "    accuracy                         0.9119       579\n",
      "   macro avg     0.7860    0.7730    0.7463       579\n",
      "weighted avg     0.9344    0.9119    0.9176       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_conf.reshape(-1), Y_pred_deconfModel_confTest_gmm, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf894e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9959    0.9742    0.9849       503\n",
      "         1.0     0.6842    1.0000    0.8125        13\n",
      "         2.0     1.0000    0.9512    0.9750        41\n",
      "         3.0     0.7647    1.0000    0.8667        13\n",
      "         4.0     1.0000    1.0000    1.0000         5\n",
      "         5.0     0.5714    1.0000    0.7273         4\n",
      "\n",
      "    accuracy                         0.9741       579\n",
      "   macro avg     0.8360    0.9876    0.8944       579\n",
      "weighted avg     0.9811    0.9741    0.9760       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_deconf.reshape(-1), Y_pred_deconfModel_deconfTest_gmm, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e2885",
   "metadata": {},
   "source": [
    "#### Clear the GPU memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a9d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2103"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0627752",
   "metadata": {},
   "source": [
    "### Deconfounded ResNet-CNN using CB-based decofounding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451414a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the machanism learning pipeline using CB-based deconfounding method\n",
    "ml_cb_pipeline = mlpipe.mechanism_learning_process(cause_data = cause_category,\n",
    "                                                   mechanism_data = mediaor_values, \n",
    "                                                   effect_data = effect_imgs_lowd_embedding, \n",
    "                                                   intv_values = np.unique(cause_category), \n",
    "                                                   dist_map = None, \n",
    "                                                   est_method = \"kde\",\n",
    "                                                   bandwidth = \"scott\"\n",
    "                                                   )\n",
    "# Resample the data using the front-door CB\n",
    "X_train_deconf_cb, Y_train_deconf_cb = ml_cb_pipeline.cb_resample(n_samples = 5000,\n",
    "                                                                  cb_mode = \"fast\",\n",
    "                                                                  return_samples = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the sampled image embedding to the original space\n",
    "X_train_deconf_cb = img_pca.inverse_transform(X_train_deconf_cb)\n",
    "# Clip the X values to be in the range of [0, 255] as the original images\n",
    "X_train_deconf_cb = np.clip(X_train_deconf_cb, 0, 255.0)\n",
    "# Reshape the data to the original image shape\n",
    "X_train_deconf_cb = X_train_deconf_cb.reshape(-1,image_h,image_w,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1bb263",
   "metadata": {},
   "source": [
    "#### Compile and train the CB-based deconfounded ResNet-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9427d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "7500/7500 [==============================] - 36s 4ms/step - loss: 0.7422 - accuracy: 0.7564 - val_loss: 0.4462 - val_accuracy: 0.8886\n",
      "Epoch 2/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.3127 - accuracy: 0.9031 - val_loss: 0.4439 - val_accuracy: 0.8964\n",
      "Epoch 3/75\n",
      "7500/7500 [==============================] - 34s 4ms/step - loss: 0.2513 - accuracy: 0.9240 - val_loss: 0.4033 - val_accuracy: 0.9223\n",
      "Epoch 4/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.2397 - accuracy: 0.9277 - val_loss: 0.3951 - val_accuracy: 0.9145\n",
      "Epoch 5/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2118 - accuracy: 0.9343 - val_loss: 0.3974 - val_accuracy: 0.9067\n",
      "Epoch 6/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.2104 - accuracy: 0.9376 - val_loss: 0.4929 - val_accuracy: 0.8886\n",
      "Epoch 7/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.2020 - accuracy: 0.9383 - val_loss: 0.5028 - val_accuracy: 0.8731\n",
      "Epoch 8/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1987 - accuracy: 0.9372 - val_loss: 0.5035 - val_accuracy: 0.8627\n",
      "Epoch 9/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.1882 - accuracy: 0.9409 - val_loss: 0.5126 - val_accuracy: 0.8808\n",
      "Epoch 10/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.2066 - accuracy: 0.9398 - val_loss: 0.5792 - val_accuracy: 0.8860\n",
      "Epoch 11/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.1946 - accuracy: 0.9414 - val_loss: 0.4799 - val_accuracy: 0.8886\n",
      "Epoch 12/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.1941 - accuracy: 0.9394 - val_loss: 0.5508 - val_accuracy: 0.8938\n",
      "Epoch 13/75\n",
      "7500/7500 [==============================] - 38s 5ms/step - loss: 0.1882 - accuracy: 0.9422 - val_loss: 0.5728 - val_accuracy: 0.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25397bcf490>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet_cb_deconf = resNetCNN_model((image_h, image_w, 1), n_class)\n",
    "ResNet_cb_deconf.compile(optimizer='adam',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "Y_train_deconf_cb_oh = to_categorical(Y_train_deconf_cb.reshape(-1), num_classes=n_class)\n",
    "Y_val_deconf_oh = to_categorical(Y_val_deconf.reshape(-1), num_classes=n_class)\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=10, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "ResNet_cb_deconf.fit(X_train_deconf_cb, Y_train_deconf_cb_oh, \n",
    "                      epochs=75, batch_size=4, shuffle=True,\n",
    "                      validation_data=(X_val_deconf, Y_val_deconf_oh),\n",
    "                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47743059",
   "metadata": {},
   "source": [
    "#### Predict on synthetic \"non-confounded\" and confounded test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "119d16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step\n",
      "19/19 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_deconfModel_confTest_cb = ResNet_cb_deconf.predict(X_test_conf.reshape(-1, image_h, image_w, 1))\n",
    "Y_pred_deconfModel_deconfTest_cb = ResNet_cb_deconf.predict(X_test_deconf.reshape(-1, image_h, image_w, 1))\n",
    "Y_pred_deconfModel_confTest_cb = np.argmax(Y_pred_deconfModel_confTest_cb, axis=1)\n",
    "Y_pred_deconfModel_deconfTest_cb = np.argmax(Y_pred_deconfModel_deconfTest_cb, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676d77b",
   "metadata": {},
   "source": [
    "#### Evaluate the model performance on confounded and synthetic \"non-confounded\" test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32824b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9886    0.8588    0.9191       503\n",
      "         1.0     0.4762    0.7692    0.5882        13\n",
      "         2.0     0.4872    0.9268    0.6387        41\n",
      "         3.0     0.4194    1.0000    0.5909        13\n",
      "         4.0     0.5556    1.0000    0.7143         5\n",
      "         5.0     1.0000    0.7500    0.8571         4\n",
      "\n",
      "    accuracy                         0.8653       579\n",
      "   macro avg     0.6545    0.8842    0.7181       579\n",
      "weighted avg     0.9251    0.8653    0.8823       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_conf.reshape(-1), Y_pred_deconfModel_confTest_cb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "338ea6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9332    0.9722    0.9523       503\n",
      "         1.0     1.0000    0.1538    0.2667        13\n",
      "         2.0     0.7500    0.7317    0.7407        41\n",
      "         3.0     0.6250    0.3846    0.4762        13\n",
      "         4.0     0.5000    0.4000    0.4444         5\n",
      "         5.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.9119       579\n",
      "   macro avg     0.6347    0.4404    0.4801       579\n",
      "weighted avg     0.9046    0.9119    0.9003       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_deconf.reshape(-1), Y_pred_deconfModel_deconfTest_cb, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebba6d",
   "metadata": {},
   "source": [
    "#### Clear the GPU memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1137a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e6ec7",
   "metadata": {},
   "source": [
    "### Confounded model\n",
    "#### Resample the confounded training dataset using ramdom oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0882824",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conf_resampled = np.empty((0, image_h*image_w))\n",
    "Y_train_conf_resampled = np.empty((0, 1))\n",
    "\n",
    "for class_i in range(n_class):\n",
    "    idx_class_i = np.where(Y_train_conf == class_i)[0]\n",
    "    random_sample_idx = np.random.choice(idx_class_i, n_train_sample[class_i], replace=True)\n",
    "    X_train_conf_resampled = np.vstack((X_train_conf_resampled, X_train_conf[random_sample_idx]))\n",
    "    Y_train_conf_resampled = np.vstack((Y_train_conf_resampled, Y_train_conf[random_sample_idx]))\n",
    "X_train_conf = X_train_conf_resampled.reshape(-1, image_h, image_w, 1)\n",
    "Y_train_conf = Y_train_conf_resampled.reshape(-1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75abf9e",
   "metadata": {},
   "source": [
    "#### Compile and train the ResNet-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e0c292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "7500/7500 [==============================] - 38s 4ms/step - loss: 0.4093 - accuracy: 0.9035 - val_loss: 0.5714 - val_accuracy: 0.8575\n",
      "Epoch 2/75\n",
      "7500/7500 [==============================] - 32s 4ms/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 0.6363 - val_accuracy: 0.9171\n",
      "Epoch 3/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.0451 - accuracy: 0.9878 - val_loss: 0.7903 - val_accuracy: 0.8808\n",
      "Epoch 4/75\n",
      "7500/7500 [==============================] - 31s 4ms/step - loss: 0.0353 - accuracy: 0.9911 - val_loss: 1.0657 - val_accuracy: 0.9093\n",
      "Epoch 5/75\n",
      "7500/7500 [==============================] - 31s 4ms/step - loss: 0.0304 - accuracy: 0.9929 - val_loss: 1.1244 - val_accuracy: 0.9223\n",
      "Epoch 6/75\n",
      "7500/7500 [==============================] - 32s 4ms/step - loss: 0.0394 - accuracy: 0.9922 - val_loss: 0.8585 - val_accuracy: 0.9249\n",
      "Epoch 7/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.0315 - accuracy: 0.9932 - val_loss: 1.4339 - val_accuracy: 0.9301\n",
      "Epoch 8/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.0307 - accuracy: 0.9944 - val_loss: 0.8270 - val_accuracy: 0.9326\n",
      "Epoch 9/75\n",
      "7500/7500 [==============================] - 28s 4ms/step - loss: 0.0310 - accuracy: 0.9940 - val_loss: 1.0560 - val_accuracy: 0.9326\n",
      "Epoch 10/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.0287 - accuracy: 0.9949 - val_loss: 1.9580 - val_accuracy: 0.9223\n",
      "Epoch 11/75\n",
      "7500/7500 [==============================] - 33s 4ms/step - loss: 0.0308 - accuracy: 0.9945 - val_loss: 1.0804 - val_accuracy: 0.9326\n",
      "Epoch 12/75\n",
      "7500/7500 [==============================] - 35s 5ms/step - loss: 0.0481 - accuracy: 0.9937 - val_loss: 1.6563 - val_accuracy: 0.9249\n",
      "Epoch 13/75\n",
      "7500/7500 [==============================] - 32s 4ms/step - loss: 0.0325 - accuracy: 0.9942 - val_loss: 0.9888 - val_accuracy: 0.9456\n",
      "Epoch 14/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.0266 - accuracy: 0.9957 - val_loss: 1.4820 - val_accuracy: 0.9249\n",
      "Epoch 15/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.0413 - accuracy: 0.9951 - val_loss: 1.7143 - val_accuracy: 0.9223\n",
      "Epoch 16/75\n",
      "7500/7500 [==============================] - 34s 5ms/step - loss: 0.0319 - accuracy: 0.9953 - val_loss: 1.6152 - val_accuracy: 0.9404\n",
      "Epoch 17/75\n",
      "7500/7500 [==============================] - 31s 4ms/step - loss: 0.0337 - accuracy: 0.9951 - val_loss: 1.5497 - val_accuracy: 0.9275\n",
      "Epoch 18/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.0350 - accuracy: 0.9952 - val_loss: 1.5811 - val_accuracy: 0.9197\n",
      "Epoch 19/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.0403 - accuracy: 0.9950 - val_loss: 2.2192 - val_accuracy: 0.9326\n",
      "Epoch 20/75\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.0350 - accuracy: 0.9952 - val_loss: 2.2113 - val_accuracy: 0.9404\n",
      "Epoch 21/75\n",
      "7500/7500 [==============================] - 32s 4ms/step - loss: 0.0294 - accuracy: 0.9959 - val_loss: 1.6056 - val_accuracy: 0.9301\n",
      "Epoch 22/75\n",
      "7500/7500 [==============================] - 28s 4ms/step - loss: 0.0320 - accuracy: 0.9963 - val_loss: 1.4814 - val_accuracy: 0.9326\n",
      "Epoch 23/75\n",
      "7500/7500 [==============================] - 36s 5ms/step - loss: 0.0283 - accuracy: 0.9957 - val_loss: 2.8312 - val_accuracy: 0.9378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253909a3c40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_conf_oh = to_categorical(Y_train_conf, num_classes=n_class)\n",
    "Y_val_conf_oh = to_categorical(Y_val_conf, num_classes=n_class)\n",
    "\n",
    "ResNet_conf = resNetCNN_model((image_h, image_w, 1), n_class)\n",
    "ResNet_conf.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
    "                            patience=10, verbose=0, mode='max',\n",
    "                            baseline=None, restore_best_weights=True)\n",
    "\n",
    "ResNet_conf.fit(X_train_conf.reshape(-1, image_h, image_w, 1), Y_train_conf_oh, \n",
    "               epochs=75, batch_size=4, shuffle=True,\n",
    "               validation_data=(X_val_conf.reshape(-1, image_h, image_w, 1), Y_val_conf_oh),\n",
    "               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0356536",
   "metadata": {},
   "source": [
    "#### Predict on synthetic \"non-confounded\" and confounded test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b06a8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step\n",
      "19/19 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_confModel_confTest = ResNet_conf.predict(X_test_conf.reshape(-1, image_h, image_w, 1))\n",
    "Y_pred_confModel_deconfTest = ResNet_conf.predict(X_test_deconf.reshape(-1, image_h, image_w, 1))\n",
    "Y_pred_confModel_confTest = np.argmax(Y_pred_confModel_confTest, axis=1)\n",
    "Y_pred_confModel_deconfTest = np.argmax(Y_pred_confModel_deconfTest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce05ae",
   "metadata": {},
   "source": [
    "#### Evaluate the model performance on confounded and synthetic \"non-confounded\" test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87b741f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9592    0.9821    0.9705       503\n",
      "         1.0     0.4545    0.3846    0.4167        13\n",
      "         2.0     0.9667    0.7073    0.8169        41\n",
      "         3.0     0.8000    0.9231    0.8571        13\n",
      "         4.0     0.5714    0.8000    0.6667         5\n",
      "         5.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.9396       579\n",
      "   macro avg     0.6253    0.6329    0.6213       579\n",
      "weighted avg     0.9349    0.9396    0.9353       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_conf.reshape(-1), Y_pred_confModel_confTest, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33d0520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8822    0.9980    0.9366       503\n",
      "         1.0     0.7500    0.2308    0.3529        13\n",
      "         2.0     1.0000    0.0976    0.1778        41\n",
      "         3.0     1.0000    0.1538    0.2667        13\n",
      "         4.0     0.0000    0.0000    0.0000         5\n",
      "         5.0     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.8826       579\n",
      "   macro avg     0.6054    0.2467    0.2890       579\n",
      "weighted avg     0.8765    0.8826    0.8401       579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_deconf.reshape(-1), Y_pred_confModel_deconfTest, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17dbdf",
   "metadata": {},
   "source": [
    "#### Clear the GPU memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
